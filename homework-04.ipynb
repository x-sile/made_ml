{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './corpora'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'AnnaKarenina.txt'), 'r') as f1, \\\n",
    "     open(os.path.join(DATA_PATH, 'WarAndPeace.txt'), 'r') as f2:\n",
    "    anna_karenina = f1.read().lower()\n",
    "    war_and_peace = f2.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Униграммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(text):\n",
    "    return ''.join(l for l in text.lower() if l in ALPHABET)\n",
    "\n",
    "def get_unigram_freqs(text):\n",
    "    freqs = Counter(text)\n",
    "    freqs = {k: v / sum(freqs.values()) for k, v in freqs.items()}\n",
    "    freqs = dict(sorted(freqs.items(), key=lambda x: x[1], reverse=True))\n",
    "    return freqs\n",
    "\n",
    "def unigram_encode_decode(text, mapping):\n",
    "    return ''.join([mapping[l] for l in text])\n",
    "\n",
    "def get_encode_mapping(orig_freqs):\n",
    "    return dict(zip(orig_freqs, np.random.permutation(list(orig_freqs))))\n",
    "\n",
    "def get_decode_mapping(orig_freqs, text_freqs):\n",
    "    return dict(zip(text_freqs, orig_freqs))\n",
    "\n",
    "def accuracy(orig_text, decoded_text):\n",
    "    return sum(np.array(list(orig_text)) == np.array(list(decoded_text))) / len(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = filter_text(anna_karenina + war_and_peace)\n",
    "\n",
    "unigram_freqs = get_unigram_freqs(train_texts)\n",
    "encode_mapping = get_encode_mapping(unigram_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "Да, но не знать о Солнечной системе!.. – воскликнул я. \n",
    "– На кой черт она мне? – перебил он нетерпеливо. \n",
    "– Ну хорошо, пусть, как вы говорите, мы вращаемся вокруг Солнца. \n",
    "А если бы я узнал, что мы вращаемся вокруг Луны, \n",
    "много бы это помогло мне или моей работе? Я хотел было спросить, что же это за работа, но почувствовал, что он будет недоволен. \n",
    "Я задумался над нашим коротким разговором и попытался сделать кое-какие выводы. \n",
    "Он не хочет засорять голову знаниями, которые не нужны для его целей. \n",
    "Стало быть, все накопленные знания он намерен так или иначе использовать. \n",
    "Я перечислил в уме все области знаний, в которых он проявил отличную осведомленность. \n",
    "Я даже взял карандаш и записал все это на бумаге. \n",
    "Перечитав список, я не мог удержаться от улыбки. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text = filter_text(test_text)\n",
    "encoded_text = unigram_encode_decode(filtered_text, encode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_unigram_freqs = get_unigram_freqs(encoded_text)\n",
    "decode_mapping = get_decode_mapping(unigram_freqs, text_unigram_freqs)\n",
    "\n",
    "decoded_text = unigram_encode_decode(encoded_text, decode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "да но не знать о солнечной системе  воскликнул я  на кой черт она мне  перебил он нетерпеливо  ну хорошо пусть как вы говорите мы вращаемся вокруг солнца а если бы я узнал что мы вращаемся вокруг луны много бы это помогло мне или моей работе я хотел было спросить что же это за работа но почувствовал что он будет недоволен я задумался над нашим коротким разговором и попытался сделать коекакие выводы он не хочет засорять голову знаниями которые не нужны для его целей стало быть все накопленные знания он намерен так или иначе использовать я перечислил в уме все области знаний в которых он проявил отличную осведомленность я даже взял карандаш и записал все это на бумаге перечитав список я не мог удержаться от улыбки \n"
     ]
    }
   ],
   "source": [
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ьн ао ае ганиз о лотаеыаож лслиеке  волдтсдаут м  ан дож ыери оан кае  яеребст оа аеиеряетсво  ау йорохо яулиз днд вп човорсие кп врнэнеклм водруч лотацн н елтс бп м угант ыио кп врнэнеклм водруч туап каочо бп юио яокочто кае стс коеж рнбоие м йоиет бпто ляролсиз ыио ше юио гн рнбоин ао яоыувливовнт ыио оа буьеи аеьовотеа м гньукнтлм ань анхск дороидск рнгчоворок с яояпинтлм льетниз доедндсе впвоьп оа ае йоыеи гнлормиз чотову ганасмкс доиорпе ае аушап ьтм ечо цетеж линто бпиз вле андоятеаапе ганасм оа анкереа инд стс саные сляотзговниз м яереыслтст в уке вле обтнлис ганасж в доиорпй оа яромвст оитсыаущ олвеьоктеааолиз м ьнше вгмт днрнаьнх с гняслнт вле юио ан букнче яереысинв ляслод м ае коч уьершнизлм ои утпбдс \n"
     ]
    }
   ],
   "source": [
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символов: 0.4626\n"
     ]
    }
   ],
   "source": [
    "print(f'Доля верно расшифрованных символов: {accuracy(filtered_text, decoded_text):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде как доля верно расшифрованных символов нормальная, но прочитать текст не представляется возможным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Биграммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_freqs(text):\n",
    "    freqs = Counter([text[i:i+2] for i in range(len(text) - 2)])\n",
    "    freqs = {k: v / sum(freqs.values()) for k, v in freqs.items()}\n",
    "    freqs = dict(sorted(freqs.items(), key=lambda x: x[1], reverse=True))\n",
    "    return freqs\n",
    "\n",
    "def bigram_decode(text, mapping):\n",
    "    UNKNOWN = '?'\n",
    "    decoded_text = [UNKNOWN] * len(text) \n",
    "    for text_bi, orig_bi in mapping.items(): # сначала заполняем самые частотные\n",
    "        index = text.find(text_bi)\n",
    "        while index != -1:\n",
    "            if decoded_text[index] == UNKNOWN:\n",
    "                decoded_text[index] = orig_bi[0]\n",
    "            if decoded_text[index + 1] == UNKNOWN:\n",
    "                decoded_text[index + 1] = orig_bi[1] \n",
    "            index = text.find(text_bi, index + 1)\n",
    "\n",
    "    return ''.join(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_freqs = get_bigram_freqs(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bigram_freqs = get_bigram_freqs(encoded_text)\n",
    "decode_mapping = get_decode_mapping(bigram_freqs, text_bigram_freqs)\n",
    "\n",
    "decoded_text = bigram_decode(encoded_text, decode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символов: 0.1233\n"
     ]
    }
   ],
   "source": [
    "print(f'Доля верно расшифрованных символов: {accuracy(filtered_text, decoded_text):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и и аи о а сто а о б пем оноул р о  но ягоя мя е и сио отионв в сиа о ь онаноя вои ппонрего а и мак тчуа  ялтотота ннелр отапо ан нй ь т ое ноти  но бсп и иэкгоиннее ер ся иаа ан нй ь т ое ноти  зкдбнеам ла ннееаа  ме р а а о огокагвотй у ко е к кря нк а ос ч атотиаа то еаа а ий у к и а  мячал  оа я иаа вовнутвви плр об опе аелит доеи сли сдсдко т касдий тлр отчевнь меот дое отн етото ввтасо нв ойн вои о к етвнаее титотл браона сигишнко алтео  о  ммбневбе эла ьн  оно  да нкто нно  с  ек гбыо а сиге вои саонаовтьавогоио сео о о брсраетоте  онаеу гоя нтеао нно вшисл нна сиго нко алтег воь  чаноя вкгою мн в еслсек гм лтоте илто нюея оий иилдвннаеау  я нно еааи синитрхо  онаеатьоносу рдпеи о а  тетонретоое вкаеесхани\n"
     ]
    }
   ],
   "source": [
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало еще хуже, но оно и понятно - количество биграмм сильно больше, чем букв, попасть сложнее. Думаю, можно лучше, если декодировать по-умному."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3  - MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм похож на генетический. Повторяем n_iter раз:\n",
    "- Меняем местами две случайные буквы в ключе расшифровки\n",
    "- Оцениваем вероятность получить такой текст. У нас есть наша \"языковая модель\", построенная на тренировочных текстах. Из нее мы знаем вероятности встретить биграммы. Таким образом, мы можем посчитать likelihood декодированного текста как произведение вероятностей для всех биграмм в нем.\n",
    "- Принимаем или отклоняем новый ключ шифрования (если новый likelihood больше, то принимаем, если меньше, то принимаем с вероятностью new_llh / old_llh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC:\n",
    "    \n",
    "    def __init__(self, known_freqs, alphabet, n_iter=20000, verbose=5000):\n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        self.known_freqs = known_freqs\n",
    "        self.alphabet = alphabet\n",
    "        \n",
    "        self.nan_replacement = 1 / len(ALPHABET) ** 2\n",
    "        \n",
    "    def loglikelihood(self, text):\n",
    "        bigram_counts = Counter([''.join(text[i: i + 2]) for i in range(len(text) - 2)])\n",
    "        return np.sum([count * np.log(self.known_freqs.get(bigram, self.nan_replacement)) \n",
    "                       for bigram, count in bigram_counts.items()])\n",
    "             \n",
    "    def _mutate(self, text):\n",
    "        letters = np.random.choice(self.alphabet, 2, replace=False)\n",
    "        for i in range(len(text)):\n",
    "            if text[i] == letters[0]:\n",
    "                text[i] = letters[1]\n",
    "            elif text[i] == letters[1]:\n",
    "                text[i] = letters[0]\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def _accept(cur_llh, new_llh):\n",
    "        if new_llh > cur_llh:\n",
    "            return True\n",
    "        return np.random.rand() < np.exp(new_llh - cur_llh)\n",
    "        \n",
    "    def decode(self, text):\n",
    "        best_decoded_text = copy(text)\n",
    "        cur_llh = best_llh = self.loglikelihood(text) \n",
    "        for iteration in tqdm(range(self.n_iter)):\n",
    "            new_text = self._mutate(copy(text))\n",
    "            new_llh = self.loglikelihood(new_text)\n",
    "            if self._accept(cur_llh, new_llh):\n",
    "                text = new_text\n",
    "                cur_llh = new_llh\n",
    "                if cur_llh > best_llh:\n",
    "                    best_llh = cur_llh\n",
    "                    best_decoded_text = copy(text)\n",
    "                    \n",
    "            if iteration % self.verbose == 0:\n",
    "                print(f'Best LLH: {best_llh}')\n",
    "                print(''.join(best_decoded_text))\n",
    "                print('--------------------------------------------------------------------------------')\n",
    "                \n",
    "        return ''.join(best_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 247/20000 [00:00<00:24, 811.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -6274.3579092772\n",
      "яхплыплъпцлхзопыпдыюлъжлычпдйдзъьъппвыднюйнлиюпкпплхпнычпжъ зпылхпьлъппмъ ъайюпылплъзъ мъюйвыпплипшы ыгыпмидзопнхнпвщпеывы йзъпьщпв хсхъьдкпвын иепдыюлёхпхпъдюйпащпкпицлхюпжзыпьщпв хсхъьдкпвын иепюилщпьлыеыпащпбзыпмыьыеюыпьлъпйюйпьыъчп хаызъпкпшызъюпащюыпдм ыдйзопжзыпфъпбзыпцхп хаызхплыпмыживдзвывхюпжзыпылпаияъзплъяывыюълпкпцхяиьхюдкплхяплхгйьпны ызнйьп хцеывы ыьпйпмымщзхюдкпдяъюхзопныънхнйъпвщвыящпылплъпшыжъзпцхды кзопеыюывипцлхлйкьйпнызы щъплъплифлщпяюкпъеыпёъюъчпдзхюыпащзопвдъплхнымюъллщъпцлхлйкпылплхьъ ълпзхнпйюйпйлхжъпйдмыюоцывхзопкпмъ ъжйдюйюпвпиьъпвдъпыаюхдзйпцлхлйчпвпнызы щшпылпм ыквйюпызюйжлитпыдвъяыьюъллыдзопкпяхфъпвцкюпнх хляхгпйпцхмйдхюпвдъпбзыплхпаиьхеъпмъ ъжйзхвпдмйдынпкплъпьыепияъ фхзодкпызпиющанйп\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5176/20000 [00:06<00:17, 841.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -3945.3524457172102\n",
      "да но не знать о солнечной системе  воскликнул я  на кой черт она мне  перебил он нетерпеливо  ну гороёо пусть как вы ховорите мы враъаемся вокрух солнца а если бы я узнал что мы враъаемся вокрух луны мнохо бы это помохло мне или моей работе я готел было спросить что же это за работа но почувствовал что он будет недоволен я задумался над наёим коротким разховором и попытался сделать коекакие выводы он не гочет засорять холову знаниями которые не нужны для ехо целей стало быть все накопленные знания он намерен так или иначе использовать я перечислил в уме все области знаний в которыг он проявил отличную осведомленность я даже взял карандаё и записал все это на бумахе перечитав список я не мох удержаться от улыбки \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 10194/20000 [00:12<00:11, 844.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -3928.435222215997\n",
      "да но не знать о солнечной системе  воскликнул я  на кой черт она мне  перебил он нетерпеливо  ну хороёо пусть как вы говорите мы враъаемся вокруг солнца а если бы я узнал что мы враъаемся вокруг луны много бы это помогло мне или моей работе я хотел было спросить что же это за работа но почувствовал что он будет недоволен я задумался над наёим коротким разговором и попытался сделать коекакие выводы он не хочет засорять голову знаниями которые не нужны для его целей стало быть все накопленные знания он намерен так или иначе использовать я перечислил в уме все области знаний в которых он проявил отличную осведомленность я даже взял карандаё и записал все это на бумаге перечитав список я не мог удержаться от улыбки \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 15210/20000 [00:18<00:05, 844.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -3928.435222215997\n",
      "да но не знать о солнечной системе  воскликнул я  на кой черт она мне  перебил он нетерпеливо  ну хороёо пусть как вы говорите мы враъаемся вокруг солнца а если бы я узнал что мы враъаемся вокруг луны много бы это помогло мне или моей работе я хотел было спросить что же это за работа но почувствовал что он будет недоволен я задумался над наёим коротким разговором и попытался сделать коекакие выводы он не хочет засорять голову знаниями которые не нужны для его целей стало быть все накопленные знания он намерен так или иначе использовать я перечислил в уме все области знаний в которых он проявил отличную осведомленность я даже взял карандаё и записал все это на бумаге перечитав список я не мог удержаться от улыбки \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:23<00:00, 842.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'да но не знать о солнечной системе  воскликнул я  на кой черт она мне  перебил он нетерпеливо  ну хороёо пусть как вы говорите мы враъаемся вокруг солнца а если бы я узнал что мы враъаемся вокруг луны много бы это помогло мне или моей работе я хотел было спросить что же это за работа но почувствовал что он будет недоволен я задумался над наёим коротким разговором и попытался сделать коекакие выводы он не хочет засорять голову знаниями которые не нужны для его целей стало быть все накопленные знания он намерен так или иначе использовать я перечислил в уме все области знаний в которых он проявил отличную осведомленность я даже взял карандаё и записал все это на бумаге перечитав список я не мог удержаться от улыбки '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc = MCMC(bigram_freqs, list(ALPHABET))\n",
    "\n",
    "mcmc.decode(list(encoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаю, что удалось расшифровать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Расшифровка сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_decode = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_decode_unigram_freqs = get_unigram_freqs(to_decode)\n",
    "to_decode_mapping = get_decode_mapping(unigram_freqs, to_decode_unigram_freqs)\n",
    "\n",
    "to_decode_text = unigram_encode_decode(to_decode, to_decode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "олна рд раяасо иевьтнуидг ана пемса иевьтнуидг соклс б шсеые леезжоиач кесевдг ноыке пвемастсу лкевоо рлоые рд рло ляонтна пвтрануие а пенбмасо ьтклаьтнуидг зтнн йт пелнояиоо мосровсео йтятиао кбвлт хесч кеиомие ч иамоые ио езожтю\n"
     ]
    }
   ],
   "source": [
    "print(to_decode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 568/50000 [00:00<00:26, 1861.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -1547.4474736920654\n",
      "олна рд раяасо иевьтнуидг ана пемса иевьтнуидг соклс б шсеые леезжоиач кесевдг ноыке пвемастсу лкевоо рлоые рд рло ляонтна пвтрануие а пенбмасо ьтклаьтнуидг зтнн йт пелнояиоо мосровсео йтятиао кбвлт хесч кеиомие ч иамоые ио езожтю\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10564/50000 [00:05<00:19, 1984.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -1233.8237303205765\n",
      "если вы вимите нордальный или почти нордальный текст у этого соожёения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожеёаш\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 20530/50000 [00:10<00:14, 1980.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -1232.7373345243193\n",
      "если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешах\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 30472/50000 [00:15<00:09, 1969.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -1232.7373345243193\n",
      "если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешах\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 40593/50000 [00:20<00:04, 1986.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LLH: -1232.7373345243193\n",
      "если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешах\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:25<00:00, 1964.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешах'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc = MCMC(bigram_freqs, list(ALPHABET), n_iter=50000, verbose=10000)\n",
    "\n",
    "mcmc.decode(list(to_decode_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст прочитать можно=) считаю, что расшифровка удалась"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
